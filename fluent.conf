<source>
  @type forward
  #type tail
  read_from_head true
  path /var/lib/docker/containers/*/*-json.log
  pos_file /var/log/position/fluent-docker.pos
  #nared volume za pos file
  time_format %Y-%m-%dT%H:%M:%S
  tag *
  format json
</source>
 Using filter to add container IDs to each event
<filter docker.var.lib.docker.containers.*.*-json.log>
  type record_transformer
  <record>
    container_id ${tag_parts[5]}
  </record>
</filter>
# create raw docker config, with s3 backup plugin

<match docker.*>
  type elasticsearch
  logstash_format true
  host $ES_HOST # dynamically configured to use Docker's link feature
  port 9200
  flush_interval 5s
</match>

<match docker.*>
  type s3
  aws_key_id $AWS_KID
  aws_sec_key $AWS_KEY
  s3_bucket kops-ss
  s3_region eu-central-1
  s3_object_key_format %{path}%{time_slice}_%{index}.%{file_extension}
  path fluent_logs/
  buffer_path /var/log/fluent/s3
  time_slice_format %Y%m%d-%H
  time_slice_wait 10m
  utc
</match>
